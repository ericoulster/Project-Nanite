{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import string\n",
    "import re\n",
    "import fileinput\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from striprtf.striprtf import rtf_to_text\n",
    "import docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supporting 3 standards to start: txt, docx, and rtf.\n",
    "# Maybe have another function which assumes inputs.\n",
    "\n",
    "# Textract seems to do all these things for me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = re.compile(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_strip = str.maketrans('', '', string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor filepath in glob.glob(os.path.join(project_folder, \\'*.txt\\')):\\n    # opens files in the loop\\n    with open(filepath, \"r\", encoding=\\'utf8\\') as file:\\n        # reading files\\n        content = file.read()\\n        # tokenizing words, then filtering\\n        filetoken = content.translate(punctuation_strip).split(\\' \\')\\n        wordcount = list(filter(r.match, filetoken)).len()\\n        # getting \\'length\\' of list (# of words) then appending to file\\n        wordcount_list = len(wordcount)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for filepath in glob.glob(os.path.join(project_folder, '*.txt')):\n",
    "    # opens files in the loop\n",
    "    with open(filepath, \"r\", encoding='utf8') as file:\n",
    "        # reading files\n",
    "        content = file.read()\n",
    "        # tokenizing words, then filtering\n",
    "        filetoken = content.translate(punctuation_strip).split(' ')\n",
    "        wordcount = list(filter(r.match, filetoken)).len()\n",
    "        # getting 'length' of list (# of words) then appending to file\n",
    "        wordcount_list = len(wordcount)\n",
    "\"\"\" # old        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define content, open it, and read it in prior to the function\n",
    "\n",
    "def wordcount(content):\n",
    "    filetoken = content.translate(punctuation_strip).split(' ')\n",
    "    wordcount = list(filter(r.match, filetoken))\n",
    "    return len(wordcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def textract_filepull(project_path, filetype=\\'txt\\', isDirectory=False):\\n    if isDirectory is False:\\n        filepath = os.path.join(project_path)\\n        file = textract.process(filepath)\\n        return file.decode(\"utf-8\")\\n\\n    if isDirectory is True:\\n        file_list = []\\n        for filepath in glob.glob(os.path.join(project_path, \\'*.\\' + str(filetype))):\\n            read_in = textract.process(filepath)\\n            file_list.append(read_in.decode(\"utf-8\"))\\n        merged_files = (\" \").join(file_list)\\n        return merged_files'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def textract_filepull(project_path, filetype='txt', isDirectory=False):\n",
    "    if isDirectory is False:\n",
    "        filepath = os.path.join(project_path)\n",
    "        file = textract.process(filepath)\n",
    "        return file.decode(\"utf-8\")\n",
    "\n",
    "    if isDirectory is True:\n",
    "        file_list = []\n",
    "        for filepath in glob.glob(os.path.join(project_path, '*.' + str(filetype))):\n",
    "            read_in = textract.process(filepath)\n",
    "            file_list.append(read_in.decode(\"utf-8\"))\n",
    "        merged_files = (\" \").join(file_list)\n",
    "        return merged_files\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filepull(project_path, filetype='txt', isDirectory=False):\n",
    "    \n",
    "    if isDirectory is False:\n",
    "        if filetype == 'txt':\n",
    "            filepath = os.path.join(project_path)\n",
    "            with open(filepath, \"r\", encoding='utf8') as file:\n",
    "                return file.read()\n",
    "            \n",
    "        elif filetype == 'rtf':\n",
    "            filepath = os.path.join(project_path)\n",
    "            with open(filepath, \"r\", encoding='utf8') as file:\n",
    "                rtf_file = file.read()\n",
    "                clean_file = rtf_to_text(rtf_file)\n",
    "                return clean_file\n",
    "                \n",
    "        elif filetype == 'docx':\n",
    "            filepath = os.path.join(project_path)\n",
    "            file = docx2txt.process(filepath)\n",
    "            return file\n",
    "\n",
    "        else:\n",
    "            print(\"error: filepull only accepts 'txt', 'rtf', & 'docx' as args\")\n",
    "    # TEST ALL THESE    \n",
    "    if isDirectory is True:\n",
    "        if filetype == 'txt':\n",
    "            file_list = []\n",
    "            for filepath in glob.glob(os.path.join(project_path, '*.' + str(filetype))):\n",
    "                with open(filepath, \"r\", encoding='utf8') as file:\n",
    "                    read_in = file.read()\n",
    "                    file_list.append(read_in)\n",
    "            merged_files = (\" \").join(file_list)\n",
    "            return merged_files\n",
    "        \n",
    "        elif filetype == 'rtf':\n",
    "            file_list = []\n",
    "            for filepath in glob.glob(os.path.join(project_path, '*.' + str(filetype))):\n",
    "                with open(filepath, \"r\", encoding='utf8') as file:\n",
    "                    rtf_file = file.read()\n",
    "                    clean_file = rtf_to_text(rtf_file)\n",
    "                    file_list.append(clean_file)\n",
    "            merged_files = (\" \").join(file_list)\n",
    "            return merged_files    \n",
    "        \n",
    "        elif filetype == 'docx':\n",
    "            file_list = []\n",
    "            for filepath in glob.glob(os.path.join(project_path, '*.' + str(filetype))):\n",
    "                file_list = docx2txt.process(filepath)\n",
    "            merged_files = (\" \").join(file_list)\n",
    "            return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = r'D:\\Documents\\Datasets\\Testing files\\rtf files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = filepull(test, filetype='rtf', isDirectory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pee is\n",
      " Stored in\n",
      " The balls\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordcount(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test this\n",
    "def wordtable_initialize(name, target, path, filetype):\n",
    "    df = pd.read_csv('wordcount_meta.csv', index_col='Project Name')\n",
    "    if name in df['Project Name'].unique() == True:\n",
    "        new_row = pd.DataFrame({'Project Name':name, 'Latest Target':target, 'Project Path':path, 'Filetype':filetype\n",
    "            }, index='Project Name')\n",
    "        df.update(new_row)\n",
    "        pd.to_csv('wordcount_meta.csv')\n",
    "    \n",
    "    else:\n",
    "        df = df.append(\n",
    "            {'Project Name':name, 'Latest Target':target, 'Project Path':path, 'Filetype':filetype\n",
    "            })\n",
    "        df.to_csv('wordcount_meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"filenames = ['file1.txt', 'file2.txt', ...]\\nwith open('path/to/output/file', 'w') as outfile:\\n    for fname in filenames:\\n        with open(fname) as infile:\\n            for line in infile:\\n                outfile.write(line)\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"filenames = ['file1.txt', 'file2.txt', ...]\n",
    "with open('path/to/output/file', 'w') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(fname) as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a function to write a project name & current wordcount goal to a .csv\n",
    "# Make a function to write-in a project's daily wordcount & it's current target"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
